---
title             : "Parents Calibrate Speech to Their Children's Vocabulary Knowledge"
shorttitle        : "Parental Speech Calibration"

author: 
  - name          : "Ashley Leung"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "5848 S University Ave, Chicago IL, 60642"
    email         : "ashleyleung@uchicago.edu"
  - name          : "Alexandra Tunkel"
    affiliation   : "1"
  - name          : "Daniel Yurovsky"
    affiliation   : "1,2"

affiliation:
  - id            : "1"
    institution   : "The University of Chicago"
  - id            : "2"
    institution   : "Carnegie Mellon University"

abstract: |
   Young children learn language at an incredible rate. While children come prepared with powerful statistical learning mechanisms, the statistics they encounter are also prepared for them: Children learn from caregivers motivated to communicate with them. Do caregivers modify their speech in order to support children's comprehension? We asked children and their parents to play a simple reference game in which the parent's goal was to guide their child to select a target animal from a set of three. We show that parents calibrate their referring expressions to their children's language knowledge, producing more informative references for animals that they thought their children did not know. Further, parents learn about their children's knowledge over the course of the game, and calibrate their referring expressions accordingly. These results underscore the importance of understanding the communicative context in which language learning happens. 

authornote: |
  All code for these analyses are available at \url{https://github.com/ashleychuikay/animalgame}

keywords          : "parent-child interaction; language development; communication"
wordcount         : "X"

bibliography      : ["animalgame.bib"]

floatsintext      : yes
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no

documentclass     : "apa6"
classoption       : "man"
output            : papaja::apa6_pdf
---

```{r setup, include = FALSE}
library(papaja)
library(tidyverse)
library(here)
library(feather)
library(tidyboot)
library(lme4)
library(knitr)
```


```{r load_data}
demos <- read_feather(here("data/demos.feather"))
word_difficulty <- read_feather(here("data/word_difficulty.feather")) %>%
    rename(understands = difficulty)
```


Children learn language at astonishing rates, acquiring thousands of words by the time they are toddlers. How do children learn so many words before they know how to dress themselves? One account for children's rapid language acquisition is statistical learning. Young children can attend to the distributional structure of language, learning to discriminate words and identify word order from speech streams [@saffran1996; @saffran2003]. Statistical learning can be a powerful tool for early language learning, and showcases the ability that children have to harvest information from their surroundings. However, the particular structure of children's language environments may also play a role in supporting language development.

The way we speak to children often differs from the way we speak to adults. Child-directed speech (CDS) exists across cultures, and is characterized by higher pitches and more exaggerated enunciations when compared to adult-directed speech (ADS) [@cooper1990; @grieser1988]. Not only do children prefer CDS over ADS, CDS is also a better predictor for language learning than overheard ADS [@shneidman2013]. CDS does not only differ from ADS in prosodic features- the structural qualities of CDS make speech segmentation and word learning easier [@thiessen2005; @yurovsky2012]. While children live in the same physical environments as adults, their *language environments* contain specific types of input that facilitate early language learning.

Children’s language environments are not only suited for their abilities; they also change across development. Parents play a role in changing their children's language environment, and there is evidence suggesting that these changes aid language development. Parents use simpler, more redundant language when talking to toddlers, and more complex syntactic structures when speaking with school-aged children [@snow1972]. Importantly, sensitive modification of parent response shapes language learning in children [@hoff-ginsberg1982; @tamis-lemonda2014]. 

Why do parents modify the way they speak according to their children? One possible explanation is that parents are actively teaching their children. Indeed, some have posited that CDS is an ostensive cue for social learning, and that infants are born prepared to attend to these cues [@csibra2009]. While it may be true that parents hope to impart knowledge to their children, we argue that effective communication is the proximal goal. The field of linguistics has long established that adults communicate in ways that are efficient. Grice's [-@grice1975] maxim of quantity states that speech should be as informative as necessary, and no more. Adults are able to adhere to these maxims, adapting speech according to conversational partners' knowledge as needed for successful communication [@clark1986]. We argue that the parent's goal to communicate with their child drives the change in language use. Specifically, parents adapt their speech according to their children's language abilities. 

Parents modify their language as a *means* to achieve successful communication. Research show that parents use simpler language and are more linguistically aligned with their younger children, and these patterns of speech change as their children develop [@snow1972; @yurovsky2016]. Parents are also sensitive to children’s vocabulary knowledge, and the way they refer to objects change markedly depending on whether they are novel, comprehended, or familiar to their children [@masur1997]. These changes in parent speech may indicate adaptations that are aimed at fulfilling the goal of effective communication, and that the language necessary to fulfill that goal changes as children develop.

Based on work by @masur1997, we developed a study to investigate how parents adapt their speech according to their children’s vocabulary knowledge. Masur’s study involved parents and children engaging in unstructured free play, and parents reported their children’s vocabulary knowledge after the session. Our study uses a structured interactive game that allows us to control for the amount and type of stimuli presented to the parent-child dyads, and parent-reported vocabulary measures are collected before the study. Our paradigm also introduces a communicative goal within a structured game, which also allows parent utterances to be more comparable across dyads.

We designed an interactive iPad game in which parents verbally guide their children to select animals on an iPad. Each animal in the game appeared as a target twice. We predicted that parents would modify their speech based on their beliefs about their children’s vocabulary knowledge. Specifically, we predicted: (1) Parents should use shorter referring expressions when describing animals that they believe their children know, and (2) Upon the second appearance of an animal, parents would adapt the length of their referring expression according to whether the child responded accurately on the first appearance of the animal.

# Method
We report how we determined our sample size, all data exclusions (if any), all manipulations, and all measures in the study. <!-- 21-word solution (Simmons, Nelson & Simonsohn, 2012; retrieved from http://ssrn.com/abstract=2160588) -->

## Participants

Toddlers (aged 2.0 to 2.5 years) and their parents were recruited from a database of families in the local community or approached on the floor of a local science museum in order to achieve a planned sample of 40 parent-child dyads. A total of 46 parent-child pairs were recruited, but data from six pairs were dropped from analysis due to experimental error or failure to complete the study. The final sample consisted of `r nrow(demos)` children aged `r min(demos$age)` to `r max(demos$age)` years ($M =$ `r mean(demos$age)`), `r demos %>% summarise(female = sum(demos == "female")) %>% pull` of whom were girls. 

## Stimuli

Eighteen animal images were selected from the @rossion2004 image set, which is a colored version of the @snodgrass1980 object set. Animals were selected based on age of acquisition (AoA), using data from WordBank [@frank2017]. The AoA of the selected animals ranged from 12 to 31 months. Half of the animals had lower AoA (12-20 months), and the other half had higher AoA (25-31 months). Each trial featured three animals, all from either the low AoA or high AoA category. 

A modified version of the MacArthur-Bates Communicative Development Inventory [CDI; @fenson2007], a parent-reported measure of children’s vocabulary, was administered before the testing session via an online survey. The selected animal words were embedded among the 85 words in the survey. Two of the animal words--one in the early AOA and one in the late AOA category--were accidentally omitted, so trials for those words were not included in analysis.

Each parent-child pair played an interactive game using two iPads. Children were given two warm-up trials to get used to the iPads. The practice and experimental trials began after the warm-up. On each trial, three images of animals were displayed side by side on the child’s screen, and a single word appeared on the parent’s screen (Figure \ref{fig:ipads}). Parents were instructed to communicate as they normally would with their child, and encourage them to choose the object corresponding to the word on their screen. The child was instructed to listen to their parent for cues. Once an animal was tapped, the trial ended, and a new trial began. There was a total of 36 experimental trials, such that each animal appeared as the target twice. Trials were randomized for each participant, with the constraint that the same animal could not be the target twice in a row. Practice trials followed the same format as experimental trials, with the exception that images of fruit and vegetables were shown. All sessions were videotaped for transcription and coding.

```{r ipads, fig.env = "figure", fig.pos = "tb", fig.align='center', fig.width=2, fig.height=2, out.width = "150px", set.cap.width=T, num.cols.cap=1, fig.cap = "Example iPad screens for the child (top) and parent (bottom) during the experiment."}
include_graphics("figs/ipads.pdf")
```

## Design and Procedure

Each parent-child pair played an interactive game using two iPads. Children were given two warm-up trials to get used to the iPads. The practice and experimental trials began after the warm-up. On each trial, three images of animals were displayed side by side on the child’s screen, and a single word appeared on the parent’s screen (Figure \ref{fig:ipads}). Parents were instructed to communicate as they normally would with their child, and encourage them to choose the object corresponding to the word on their screen. The child was instructed to listen to their parent for cues. Once an animal was tapped, the trial ended, and a new trial began. There was a total of 36 experimental trials, such that each animal appeared as the target twice. Trials were randomized for each participant, with the constraint that the same animal could not be the target twice in a row. Practice trials followed the same format as experimental trials, with the exception that images of fruit and vegetables were shown. All sessions were videotaped for transcription and coding.

## Data analysis

The data of interest in this study were parent utterances used during the interactive game and parents’ responses on the adapted CDI. Transcripts of the videos were analyzed for length of referring expressions. We measured the length of parents' referring utterances as a proxy for amount of information given in each utterance. Furthermore, utterances were manually coded for the following: use of canonical labels, descriptors, and comparison to other animals. Parent utterances irrelevant to the iPad game (e.g. asking the child to sit down) were not analyzed. Children’s utterances were coded when audible, but were not analyzed.

# Results

```{r word_difficulty}
group_difficulty <- word_difficulty %>%
  group_by(type, word) %>%
  summarise(understands = mean(understands)) %>%
  tidyboot_mean(understands)

# difficulty_lmer <- word_difficulty %>%
#   filter(type %in% c("early", "late")) %>%
#   mutate(type = factor(type, levels = c("early", "late"))) %>%
#   glmer(understands ~ type + (1|subj), family = "binomial", data = .) %>%
#   tidy() %>%
#   filter(effect == "fixed")
```


### Word difficulty. 

We first confirm that the animals predicted be later learned were less likely to be marked known by the parents of children in our studies. As predicted, animals in the early AoA category were judged to be understood by `r group_difficulty %>% filter(type == "early") %>% mutate(empirical_stat = empirical_stat * 100) %>% pull(empirical_stat) %>% round(0)`% of parents, and items in the late AoA category were judged understood by `r group_difficulty %>% filter(type == "late") %>% mutate(empirical_stat = empirical_stat * 100) %>% pull(empirical_stat) %>% round(0)`%.


# Discussion

Parents have a wealth of knowledge about their kids, including their linguistic development [@fenson2007]. Do they draw on this knowledge when they want to communicate? In a referential communication task, we showed that parents speak differently depending on their beliefs about their children's vocabulary knowledge. Specifically, they produce shorter, less informative expressions to refer to animals that they believe their children know relative to animals that they think their children do not know. Further, parents update their beliefs during the course of the task, producing more informative expressions on the second appearance of an animal they previously thought their children knew if they observed evidence to the contrary (i.e. when children selected the wrong animal). We further found that more informative referring expressions were associated with increased likelihood of successful communication: Children were more likely to correctly select animals whose names they did not know if their parents produced longer utterances to refer to them. We leveraged length as a proxy for informativeness in parents' expressions in the service of quantitative, theory-agnostic predictions. In ongoing work, we are analyzing *how* parents succeed on these trials, and investigating whether different strategies lead to different levels of success. 

In general, communicative success was high. Children selected the correct animal at above chance levels, even for targets whose names their parents thought they did not know. Because easy and hard animals appeared on separate trials, children's high accuracy in selecting unfamiliar animals is unlikely to be due to the use of strategies like mutual exclusivity [@markman1988]. Instead, parents must have produced sufficient information for their children to find the correct target. Taken together with our finding that parents used longer sentences for words they think their children do not know, our results suggest that parents modified their speech as a means to communicate. 

Our proposed explanation for these results is that they are produced by a pressure for effective communication: Parents need to produce sufficient information for their children to understand their intended meaning. That is, parents design their utterances for their children's benefit [speaker-design, @jaeger2013]. It could be instead that these utterances reflect pressure from speaking itself. For example, length of parents' utterances may reflect their difficulty in retrieving certain animal words [@macdonald2013]. We find this explanation unlikely given that parents were given the target words in written form on their iPad, essentially eliminating retrieval problems [@wingfield1968]. The fact that parents are using long and short referring expressions depending on their beliefs about children's vocabulary knowledge suggests that they are calibrating to their children.

It is important to note that our current results do not rule out the possibility that parents are engaging in pedagogy. Parents may be using longer referring expressions because they wish to teach their children certain words, and this could potentially explain why parents use longer references for words they believe their children do not know. To understand the motivations behind long and short utterances, we are currently analyzing the content of parents' speech. Preliminary qualitative analysis shows that parents use more adjectives on trials where they believe their children do not know the target word (e.g. "Pick the red lobster" instead of "Pick the lobster"). The use of adjectives on these trials may reflect an intention to teach children about a certain animal, but it could also indicate a pressure to communicate effectively. In the lobster example, the color "red" is likely a helpful cue for children, and parents may be using adjectives as a way to help children select the correct target quickly. While our current findings do not allow us to distinguish between the pedagogical and communicative hypotheses, we hope that further analysis of parents' speech will help us differentiate the two accounts.

Our work contributes to the current literature on parent-child interaction, and forms the basis for further experimental work examining the influences that parent speech has on children’s language development. In line with @masur1997, our findings provide evidence that parents calibrate speech sensitively to their children's vocabulary knowledge. These results are important in light of previous work suggesting that parent responsiveness and sensitivity shape the way young children learn language [@hoff-ginsberg1982; @tamis-lemonda2014]. Furthermore, we propose that parents are modifying their speech as a means to communicate, and that communicative intent shapes the language environments children experience. Further qualitative analysis of our dataset will shed light onto the characteristics of parent-child communication that are helpful for language acquisition.

Finally, this study highlights the importance of studying the parent-child pair as a unit, rather than viewing children as isolated learners: both parents and children contribute to the process of language development [@hoff-ginsberg1982; @brown1977]. Focusing on the interactive and communicative nature of language captures a more realistic picture of children's language environments: The input that children receive is not random – it is sensitive to their developmental level.


# Acknowledgements

This research was funded by a James S. McDonnell Foundation Scholar Award to DY.

\newpage

# References
```{r create_r-references}
#r_refs(file = "r-references.bib")
```

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id = "refs"></div>
\endgroup
