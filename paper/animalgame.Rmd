---
title: "Parents Calibrate Speech to Children's Vocabulary Knowledge"
bibliography: animalgame.bib
csl: apa6.csl
document-params: "10pt, letterpaper"

author-information: > 
 \author{Ashley Leung, Alexandra Tunkel, and Daniel Yurovsky \\
         \texttt{\{ashleyleung, aetunkel, yurovsky\}@uchicago.edu} \\
        Department of Psychology \\ University of Chicago}

abstract: >
  Young children acquire language at rapid rates, and the proposed mechanisms for learning often focus on children’s unique ability to harvest information from their environments. On the other hand, some lines of research focus on the role that parents' speech and responsiveness play in children's language learning. However, language development is not simply absorbing input- language is social in nature. We cannot ignore the communicative intent and interactive nature of language when considering how input influences children’s language development. The present study examined whether parents calibrate speech to their children’s knowledge in an interactive game. Our results show that parents modify their language according to beliefs about their children’s vocabulary knowledge, using longer sentences when describing unfamiliar objects and shorter sentences for familiar objects.

keywords:
  "parent-child interaction; language development; communication"
    
output: cogsci2016::cogsci_paper
#final-submission: \cogscifinalcopy
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=3, fig.height=3, fig.crop = F, fig.pos = "tb", fig.path='figs/',
                      echo=F, warning=F, cache=F, message=F, sanitize = T)

options(digits=2)
```

```{r, libraries}
library(png)
library(grid)
library(xtable)
library(tidyverse)
library(knitr)
library(papaja)
library(ggthemes)
library(lme4)
library(lmerTest)
library(directlabels)
library(ggrepel)
library(feather)
library(here)
library(tidyboot)
library(broom)
library(broom.mixed)

theme_set(theme_classic(base_size = 10))
```

# Introduction

Children learn language at astonishing rates, acquiring thousands of words by the time they are toddlers. How do children learn so many words before they know how to dress themselves? One account for children's rapid language acquisition is statistical learning. Young children can attend to the distributional structure of language, learning to discriminate words and identify word order from speech streams [@saffran1996; @saffran2003]. Statistical learning can be a powerful tool for early language learning, and showcases the ability that children have to harvest information from their surroundings. However, the particular structure of children's language environments may also play a role in supporting language development.

The way we speak to children often differs from the way we speak to adults. Child-directed speech (CDS) exists across cultures, and is characterized by higher pitches and more exaggerated enunciations when compared to adult-directed speech (ADS) [@cooper1990; @grieser1988]. Not only do children prefer CDS over ADS, CDS is also a better predictor for language learning than overheard ADS [@shneidman2013]. CDS does not only differ from ADS in prosodic features- the structural qualities of CDS make speech segmentation and word learning easier [@thiessen2005; @yurovsky2012]. While children live in the same physical environments as adults, their *language environments* contain specific types of input that facilitate early language learning.

Children’s language environments are not only suited for their abilities; they also change across development. Parents play a role in changing their children's language environment, and there is evidence suggesting that these changes aid language development. Parents use simpler and more redundant language when talking to toddlers, and more complex syntactic structures when speaking with school-aged children [@snow1972]. Importantly, sensitive modification of parent response shapes language learning in children [@hoff-ginsberg1982; @tamis-lemonda2014]. 

Why do parents modify the way they speak according to their children? One possible explanation is that parents are actively teaching their children. Indeed, some have posited that CDS is an ostensive cue for social learning, and that infants are born prepared to attend to these cues [@csibra2009]. While it may be true that parents hope to impart knowledge to their children, we argue that effective communication is the proximal goal. The field of linguistics has long established that adults communicate in ways that are efficient. For example, Grice's [-@grice1975] maxim of quantity states that speech should be as informative as necessary, and no more. Adults are able to adhere to these maxims, adapting speech according to conversational partners' knowledge as needed for successful communication [@clark1986]. We argue that the parent's goal to communicate with their child drives the change in language use. Specifically, parents adapt their speech according to their children's language abilities. 


Parents modify their language as a *means* to achieve successful communication. Research show that parents use simpler language and are more linguistically aligned with their younger children, and these patterns of speech change as their children develop [@snow1972; @yurovsky2016]. Parents are also sensitive to children’s vocabulary knowledge, and the way they refer to objects change markedly depending on whether they are novel, comprehended, or familiar to their children [@masur1997]. These changes in parent speech may indicate adaptations that are aimed at fulfilling the goal of effective communication, and that the language necessary to fulfill that goal changes as children develop.

Based on work by @masur1997, we developed a study to investigate how parents adapt their speech according to their children’s vocabulary knowledge. Masur’s study involved parents and children engaging in unstructured free play, and parents reported their children’s vocabulary knowledge after the session. Our study uses a structured interactive game that allows us to control for the amount and type of stimuli presented to the parent-child dyads. While experimental manipulation is not completely possible while also eliciting natural speech, our paradigm allows for more experimental control, and introducing a communicative goal within a game setting also allows parent utterances to be more comparable across dyads.

We designed an interactive iPad game in which parents verbally guide their children to select a particular animal on an iPad. The game featured 18 animals, and each animal appears as the target twice during the game. We predicted that parents would modify their speech based on their beliefs about their children’s vocabulary knowledge. Specifically, we predicted: (1) Parents should use shorter sentences when describing animals that they believe their children know, and (2) Upon the second appearance of an animal, parents would adapt the length of their sentence according to whether the child responded accurately on the first appearance of the animal.

# Method

```{r load_data}
target_data <- read_feather(here("data/target_data.feather")) %>%
    filter(phase != "during", person == "parent", !is.na(understands))

word_difficulty <- read_feather(here("data/word_difficulty.feather"))
demos <- read_feather(here("data/demos.feather"))
```

## Participants

Two to two and a half year old children and their parents were recruited from a databse of families in the local community or approached on the floor of a local science museum in order to achieve a planned sample of 40 parent-child dyads. A total of 47 parent-child pairs were recruited, but data from six pairs was dropped from analysis due to experimental error or failure to complete the study. The final sample consistend of `r nrow(demos)` children aged `r min(demos$age)` to `r max(demos$age)` years ($M =$ `r mean(demos$age)`), `r demos %>% summarise(female = sum(demos == "female")) %>% pull` of whom were girls. 

```{r word_difficulty}
group_difficulty <- word_difficulty %>%
  group_by(type, word) %>%
  summarise(understands = mean(understands)) %>%
  tidyboot_mean(understands)

difficulty_lmer <- word_difficulty %>%
  filter(type %in% c("early", "late")) %>%
  mutate(type = factor(type, levels = c("early", "late"))) %>%
  glmer(understands ~ type + (1|subj), family = "binomial", data = .) %>%
  tidy() %>%
  filter(effect == "fixed")
```


## Stimuli
Eighteen animal images were selected from @rossion2004 image set, which is a colored version of the @snodgrass1980 object set. Animals were selected based on age of acquisition (AoA), using data from WordBank [@frank2017]. The AoA of the selected animals ranged from 12 to 31 months. Half of the animals had lower AoA (12-20 months), and the other half had higher AoA (25-31 months). 

A modified version of the MacArthur-Bates Communicative Development Inventory [CDI; @fenson2007], a parent-reported measure of children’s vocabulary, was administered before the testing session via an online survey. The selected animal words were embedded among the 85 words in the survey. Two of the animal words--one in the early AOA and one in the late AOA category--were accidentally omitted, so trials for those words were not included in analysis.


## Design and Procedure
Each parent-child pair played an interactive game using two iPads. Children were given two warm-up trials to get used to tapping on an iPad. The practice and experiment trials began after the warm-up. On each trial, three images of animals were displayed side by side on the child’s screen, and a single word appeared on the parent’s screen (Figure \ref{fig:ipads}). Parents were instructed to communicate as they normally would with their child, and encourage them to choose the object corresponding to the word on their screen. The child was instructed to listen to their parent for cues. Once an animal was tapped, the trial ended, and a new trial began. There were a total of 36 experiment trials, such that each animal appeared as the target twice. Trials were randomized for each participant, with the constraint that the same animal could not be the target twice in a row. Practice trials followed the same format as experimental trials, with the exception that images of fruit and vegetables were shown. All sessions were videotaped for transcription and coding.

```{r ipads, fig.env = "figure", fig.pos = "tb", fig.align='center', fig.width=2, fig.height=2, out.width = "150px", set.cap.width=T, num.cols.cap=1, fig.cap = "Example iPad screens for the child (top) and parent (bottom) during the experiment."}
include_graphics("figs/ipads.pdf")
```

## Results

The data of interest in this study were parent utterances used during the interactive game and parents’ responses on the adapted CDI. Transcripts of the videos were analyzed for utterance length. We measured the length of parents' referring utterances as a proxy for amount of information given in each utterance. Parent utterances irrelevant to the iPad game (e.g. asking the child to sit down) were not analyzed. Children’s utterances were coded when audible, but were not analyzed.

### Word difficulty 

We first confirm that the animals predicted be later learned were less likely to be marked known by the parents of children in our studies. Analyses confirmed that animals in the early AoA category were judged to be understood by `r group_difficulty %>% filter(type == "early") %>% mutate(empirical_stat = empirical_stat * 100) %>% pull(empirical_stat) %>% round(0)`% of parents, and items in the late AoA category were judged understood by `r group_difficulty %>% filter(type == "late") %>% mutate(empirical_stat = empirical_stat * 100) %>% pull(empirical_stat) %>% round(0)`%.

```{r difficulty_fig, set.cap.width=T, num.cols.cap=1, fig.cap = "Parent responses on the CDI for the selected animal words.", fig.height = 2}
mean_word_difficulty <- word_difficulty %>%
  group_by(word) %>%
  tidyboot_mean(understands) %>%
  arrange(desc(empirical_stat))

plotting_words <- mean_word_difficulty %>%
  mutate(word = factor(word, levels = unique(word)))

ggplot(plotting_words, aes(x = word, y = empirical_stat, ymin = ci_lower, 
                            ymax = ci_upper)) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5), 
        text = element_text(size = 10)) +
  geom_pointrange(size = .3) +
  labs(y = "Parents report known", x = "") 
```

The difference between these groups was confirmed statistically with a logistic mixed effects regression with a fixed effect of AoA type and random effects of participants. The late AoA items were judged known by a significantly smaller proportion of parents ($\beta =$ `r difficulty_lmer %>% filter(term == "typelate") %>% pull(estimate)`, $t =$ `r difficulty_lmer %>% filter(term == "typelate") %>% pull(statistic)`, $p$ `r difficulty_lmer %>% filter(term == "typelate") %>% pull(p.value) %>% printp()`). Parents' judgments for each target word are shown in Figure \ref{fig:difficulty_fig}.

### Length of referring expressions

```{r trial_known_data}
trial_known_data <- target_data %>%
  mutate(phase = factor(phase, levels = c("pre", "post"), labels = c("before selection",
                                                                     "after selection")),
         understands = factor(understands, labels = c("unknown animal", "known animal"))) %>%
  group_by(phase, difficulty, understands, subj, appearance, trial_target) %>%
  summarise(length = sum(length)) 

mean_known_data <- trial_known_data %>%
  group_by(phase, understands, subj, appearance, trial_target) %>%
  summarise(length = mean(length)) %>%
  summarise(length = mean(length)) %>%
  summarise(length = mean(length)) %>%
  tidyboot_mean(length)

known_lmer <- trial_known_data %>%
  ungroup() %>%
  # mutate(phase = factor(phase, levels = c("after selection", "before selection")),
  #        understands = factor(understands, levels = c("known animal", "unknown animal"))) %>%
  lmer(length ~ phase * understands + (1|subj) + (1|trial_target), data = .) %>%
  tidy() %>%
  filter(effect == "fixed")

known_difficulty_lmer <- trial_known_data %>%
  ungroup() %>% 
  filter(phase == "before selection") %>%
  mutate(difficulty = 1 - difficulty, 
         understands = factor(understands, levels = c("known animal", "unknown animal"))) %>%
  lmer(length ~ difficulty + understands + (1|subj) + (1|trial_target), data = .) %>%
  tidy() %>%
  filter(effect == "fixed")
```

If parents calibrate their referential expressions to their children's linguistic knowledge, they should provice more information to children for whom a simple bare noun e.g. ("leopard") would be insufficient to identify the target. Parents did this in a number of ways: With one or more adjectives (e.g., "the spotted, yellow leopard"), with similes (e.g., "the one that's like a cat"), and with allusions to familiar specific animals exemplars of the category. In all of these cases, parents' would be required to produce more words. Thus, we analyzed the length of parents' referential expressions as a theory-agnostic proxy for informativeness.

We predicted that they should produce more informative--and thus longer--utterances to refer to animals that they thought their children did not know. We divided every trial of the game into phases: The time before a child selected an animal, and the time following selection until the start of the next trial. Figure \ref{fig:known_plot} shows parents’ utterance lengths for animals that they believe their children know versus those they believe their children do not know--both before their child selected an animal and after. In line with our prediction, parents used significantly longer utterances when talking about animals that they believed their children did not know. However, once the child had selected an animal, the encouragement and other conversation that followed did not differ between known and unknown animals. 

We confimed this result statistically, predicting utterance length from a mixed effects model with fixed effects of phase and animal knowledge and their interaction, and random effects of participant and item. All phase and the interaction of phase and knowledge were significant: Parents produced fewer words after selection ($\beta =$ `r known_lmer %>% filter(term == "phaseafter selection") %>% pull(estimate)`, $t =$ `r known_lmer %>% filter(term == "phaseafter selection") %>% pull(statistic)`,
$p$ `r known_lmer %>% filter(term == "phaseafter selection") %>% pull(p.value) %>% printp()`), and when the animal was known, ($\beta =$ `r known_lmer %>% filter(term == "understandsknown animal") %>% pull(estimate)`, $t =$ `r known_lmer %>% filter(term == "understandsknown animal") %>% pull(statistic)`, $p =$ `r known_lmer %>% filter(term == "understandsknown animal") %>% pull(p.value) %>% printp()`), but the change was smaller for known animals ($\beta =$ `r known_lmer %>% filter(term == "phaseafter selection:understandsknown animal") %>% pull(estimate)`, $t =$ `r known_lmer %>% filter(term == "phaseafter selection:understandsknown animal") %>% pull(statistic)`, $p =$ `r known_lmer %>% filter(term == "phaseafter selection:understandsknown animal") %>% pull(p.value) %>% printp()`). In the remainder of our analyses, we focus on utterances in the pre-selection phase of each trial as the post selection phase did not vary across trial targets.

Although each parent only gave a single bit of information about each animal--whether they thought their child knew it or not--we pooled these judgments across parents to estimate a continuous measure of difficulty (Figure \ref{fig:difficulty_fig}). If parents' utterances reflect a sensitivity to this continuous difficulty, the length of their utterances should vary smoothly with the difficulty of words. Figure \ref{fig:continuous_difficulty_fig} shows this relationship, which was confirmed by a mixed effecs model oredicting utterance length from fixed effects of difficulty and animal knowledge, and random effects of subject and trial target. Utterances were reliably longer for more difficult animals ($\beta =$ `r known_difficulty_lmer %>% filter(term == "difficulty") %>% pull(estimate)`, $t =$ `r known_difficulty_lmer %>% filter(term == "difficulty") %>% pull(statistic)`,
$p =$ `r known_difficulty_lmer %>% filter(term == "difficulty") %>% pull(p.value) %>% printp()`) over and above the increase for unknown animals ($\beta =$ `r known_difficulty_lmer %>% filter(term == "understandsunknown animal") %>% pull(estimate)`, $t =$ `r known_difficulty_lmer %>% filter(term == "understandsunknown animal") %>% pull(statistic)`,
$p =$ `r known_difficulty_lmer %>% filter(term == "understandsunknown animal") %>% pull(p.value) %>% printp()`) 

```{r known_plot, cache = T, fig.cap = "Length of parents' utterances before and after their child selected a target animal. Points indicate means, error bars indicate 95\\% confidence intervals computed by non-parametric bootstrapping", fig.height = 2}
ggplot(mean_known_data,
       aes(x = phase, y = empirical_stat, 
           ymin = ci_lower, ymax = ci_upper, color = understands,
           label = understands)) + 
  geom_pointrange(position = position_dodge(.25)) +
  scale_color_ptol() +
  labs(x = "", y = "Parents' words produced") +
  geom_dl(method = list(dl.trans(x=x +2.2), "first.points", cex=.7)) +
  theme(legend.position = "none")
```

```{r continuous_plot_data}
continuous_plot_data <- target_data %>%
  filter(phase == "pre") %>%
  group_by(trial_target, subj, appearance) %>%
  summarise(length = sum(length)) %>%
  summarise(length = mean(length)) %>%
  tidyboot_mean(length) %>%
  rename(length = empirical_stat,
         length_upper = ci_upper,
         length_lower = ci_lower) %>%
  select(-mean, -n) %>%
  left_join(mean_word_difficulty, by = c("trial_target" = "word")) %>%
  rename(understands_lower = ci_lower, understands_upper = ci_upper, 
         understands = empirical_stat) %>%
  select(-mean) %>%
  mutate(plotting_target = if_else(trial_target %in% c("squirrel", "cat", "lobster"),
                                   trial_target, as.character(NA)))
```

```{r continuous_difficulty_fig, fig.env = "figure*", fig.width=5.5, fig.height=2.5, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "Number of words in parents' referential expressions as a function of the probability that children knew the word for target animal. Points show group averaged proportions, error bars show 95\\% confidence intervals computed by non-parametric bootstrap"}
ggplot(continuous_plot_data, aes(x = understands, y = length, xmin = understands_lower,
                          xmax = understands_upper, ymin = length_lower,
                          ymax = length_upper,
                          label = plotting_target)) + 
  geom_smooth(method = "lm", se = F, color = "black") +
  geom_pointrange()+ 
  geom_errorbarh() + 
  geom_label_repel() +
  theme(legend.position = "none") +
  labs(x = "Proportion of children knowing target word", 
       y = "Parents' words produced") 
```

```{r lag_data}
lag_data <- target_data %>%
  filter(phase == "pre") %>%
  ungroup() %>%
  mutate(understands = factor(understands, levels = c(T, F), 
                              labels = c("parent believes known", "parent believes unknown"))) %>%
  mutate(correct = factor(correct, levels = c(TRUE, FALSE), 
                          labels = c("correct", "incorrect"))) %>%
  group_by(subj, phase, understands, target, appearance, correct) %>%
  summarise(length = sum(length)) %>%
  ungroup() %>%
  complete(nesting(subj, target, understands,  correct,  appearance),
           fill = list(length = 0)) %>%
  arrange(subj, understands, target,appearance, correct) %>%
  group_by(subj, understands, target) %>%
  mutate(lag_correct = lag(correct)) %>%
  filter(appearance == "second", !is.na(lag_correct)) %>%
  group_by(understands, lag_correct, subj, target) 

mean_lag_data <- lag_data %>%
  summarise(length = sum(length, na.rm = T)) %>%
  summarise(length = mean(length, na.rm = T)) %>%
  tidyboot_mean(length) 

lag_lmer <- lmer(length ~ lag_correct * understands + (1|subj) + (1|target), 
                 data = lag_data) %>%
  tidy() %>%
  filter(effect == "fixed")

```

```{r lag_plot,  fig.cap = "Length of parents' referring expressions on the second appearance of each animal. Points show group averaged proportions, error bars show 95\\% confidence intervals computed by non-parametric bootstrap.", fig.height = 2}
ggplot(mean_lag_data, aes(x = lag_correct, y = empirical_stat, 
           ymin = ci_lower, ymax = ci_upper, color = understands)) + 
  facet_wrap(~ understands) +
  geom_pointrange(position = position_dodge(.5), show.legend = F) +
  labs(x ="child's selection on previous appearance", y = "Partents' words produced") +
  scale_color_ptol()
```
We then tested our second hypothesis: Parents should modify their productions over the course of the experiment as they get evidence about their child's knowledge. Because each animal was the target twice, parents could use their child's selection on the first trial of the game to inform their referential expressions on the second appearance. Figure \ref{fig:lag_plot} shows the length of parents' referring expressions as a function of their prior belief about their child's knowledge and their child's selection on the first appearance of the target animal. As predicted, parents who thought their child knew an animal, but who observed evidence that they didn't lengthened their referring expressions on it's second appearance. Parents who thought their child did not know an animal before the start of the game did not shorten their referring expressions if their child was correct the first time. We cannot say definitely why their utterances do not change in length, but one likely candidate is that the utterances that lead to success the first time were heavily scaffolded and may not even have contained the animal's canonical label (e.g. "the one that looks like a cat" for leopard). We confirmed these results with a mixed effects model predicting length of expressions from parents' prior beliefs, their child's selection on the first trial, and their interaction and found only the interaction to be significant: Utterances were not reliabvly longer when parents thought their child did not know the animal ($\beta =$ `r lag_lmer %>% filter(term == "understandsparent believes unknown") %>% pull(estimate)`, $t =$ `r lag_lmer %>% filter(term == "understandsparent believes unknown") %>% pull(statistic)`, $p =$ `r lag_lmer %>% filter(term == "understandsparent believes unknown") %>% pull(p.value) %>% printp()`), nor when the child was incorrect on the previous trial  ($\beta =$ `r lag_lmer %>% filter(term == "lag_correctincorrect") %>% pull(estimate)`, $t =$ `r lag_lmer %>% filter(term == "lag_correctincorrect") %>% pull(statistic)`,
$p =$ `r lag_lmer %>% filter(term == "lag_correctincorrect") %>% pull(p.value) %>% printp()`, but only when the parent thought their child did not know the animal and was incorrect on the previous trial ($\beta =$ `r lag_lmer %>% filter(term == "lag_correctincorrect:understandsparent believes unknown") %>% pull(estimate)`, $t =$ `r lag_lmer %>% filter(term == "lag_correctincorrect:understandsparent believes unknown") %>% pull(statistic)`, $p =$ `r lag_lmer %>% filter(term == "understandsparent believes unknown") %>% pull(p.value) %>% printp()`)

### Children's selections

```{r test_data}
test_data <- target_data %>%
  ungroup() %>%
  mutate(understands = factor(understands, levels = c(T,F), 
                              labels = c("Knows", "Doesn't Know"))) %>%
  filter(phase == "pre", !is.na(understands)) %>%
  group_by(understands, correct,  subj, trial, trial_target, appearance) %>%
  summarise(length = log(sum(length))+1) 

test_lmer <- test_data %>%
  glmer(correct ~ length * understands + appearance + trial + 
        (1|subj) + (1|trial_target), 
      family = "binomial", 
      control = glmerControl(optimizer = "bobyqa"),
      data = .) %>%
  tidy() %>%
  filter(effect == "fixed") 

```

```{r test_model, results="asis", tab.env = "table", cache = T}
model_table <- test_lmer %>%
  select(-effect, -group,-std.error) %>%
  mutate(term = c("intercept", "length (log)", "unknown", 
                  "second appearance", "trial number", "length * unknown"),
         p.value = printp(p.value)) %>%
  rename(`t-value` = statistic,
         `p-value` = p.value) %>%
  xtable(caption = "Coefficient estimates for a mixed-effects logistic regression predicting children's success in selecting the target animal. The model was specified as \\texttt{correct $\\sim$ log(freq) * unknown + appearance + trial + (1|subj) + (1|animal)}.",
         label = "tab:test_model")


print(model_table, type = "latex", comment = F, table.placement = "tb",
      include.rownames = FALSE)
```

In our previous analyses, we showed that parents calibrated the length of their referring expressions to the their beliefs about their children's knowledge. They did this both in response to their prior beliefs (Figure \ref{fig:known_plot}), and their observations of their child's knowledge during the game (Figure \ref{fig:lag_plot}). In our final analyses, we asked whether this mattered for children's selections. Are children more likely to succeed in the task when parents' provide them well calibrated utterances? We asked this question by predicting children's selection trial by trial from a mixed effects logistic regression with fixed effects of their parents' prior beliefs about their knowledge of the target animal, whether the trial was the first or second appearance of the the target animal, the length of parents' referring expressions, and the interaction of parents' prior beliefs and the lenght of their expressions, as well as random effects of subject and trial target. Children were more likely to be correct when their parents produced longer utterances, but only for animals that their parent believed that they did not know. Thus, parents' informative utterances for unknown animals did appear to be supporting successful communication of the target animal. Table \ref{tab:test_model} shows coefficient estimates for all parameters


# Discussion

Our results indicate that parents speak differently depending on their beliefs about their children's vocabulary knowledge. Specifically, parents use shorter sentences when talking about animals that they believe their children know. Since parents completed the CDI prior to participating in our study, our data allow us to correlate parent beliefs with their behaviors. A conceptually similar observational study by @masur1997 asked parents to indicate children's vocabulary knowledge after the observational sessions. While their results also show that parents' speech differs for familiar and unfamiliar animals, it is unclear whether parents used children's responses during each session to assess children's knowledge. Our results not only corroborate their findings, but allow us to argue that parents' prior beliefs about their children's knowledge predict the way they will talk.

Contrary to our predictions, parents did not consistently modify their speech depending on their children’s response. Specifically, utterance length remained the same for words that parents think their children do not know, regardless of whether their children responded correctly. This may indicate that parent sensitivity does not emerge within the short time frame of a game. However, qualitative analysis of our transcripts may reveal more about parent behaviors in the case of unfamiliar words. Utterance length remains relatively long across the first and second appearance of these animals (see Fig. 5). It is possible that parents believe their children’s accuracy was due to their sufficient description of the animal (e.g. “the one that looks like a cat” for leopard).

Overall, children performed significantly above chance across all trials. This finding may seem surprising at first glance, given our CDI data (see Fig. 2). Given that previous studies have found the CDI to be a valid measure of children’s vocabulary [@dale1989], our results suggest that parents' behavior influences childrens' behavior. The high accuracy may reflect that parents succeeded in their goal to communicate, such that children were able to respond correctly even on unfamiliar trials. Since three animals appeared on each trial, children could have used strategies such as mutual exclusivity to find the correct target. However, since low and high AoA animals appeared separately, there may not have been many opportunities to use mutual exclusitivity. Taken together with our finding that parents used longer sentences for words they think their children do not know, our results suggest that parents modified their speech as a means to communicate.

One account for explaining our results is that communicative efficiency is driving parent behavior. Our results suggest that parents may be adhering Gricean conversational maxims when communicating with their children, using longer sentences for unfamiliar words, presumably because more information is necessary in cases where children do not know the target word. Our study analyzed utterance length as a proxy for information, but further qualitative analysis will be needed to determine whether longer utterances do indeed contain more information rather than simply consist of repeated words.

Our results can also be interpreted from a different perspective, in terms of speaker-design and listener- design theories. Proponents of speaker-design accounts argue that the speaker's own cognitive capacities, such as memory retrieval, influences the speech they produce [@macdonald2013]. On the other hand, those supporting listener-design accounts argue that the listener's needs, such as their knowledge level, drives speaker's language [@jaeger2013]. The opposing forces driving communication can be understood as the pressure to produce speech quickly within a communicative exchange (speaker-design), versus the pressure to produce speech that is understood by the partner (listener-design). Within the context of our game, our results support more strongly a listener-design account of communication. While parents could be using longer sentences for some words because those words are harder to retrieve, our design essentially rules out this possibility. On each trial, parents are given the target word on their iPad screen. In this case, speaker-design accounts should predict that parents will also simply say the word given to them, as that is the least cognitively taxing option. The fact that parents are using long and short sentences depending on their beliefs about children's vocabulary knowledge suggests that they are calibrating to their children.

It is important to note that our current results do not rule out the possibility that parents are engaging in pedagody. Parents may be using longer utterances because they wish to teach their children certain words. This account potentially explains why parents use longer sentences for words they believe their children do not know, and our current analysis does not allow us to distinguish between the the pedagogical and communicative hypotheses. However, analyzing the content of parents' speech will be helpful in understanding the motivations behind long and short utterances. While full qualitative analysis is underway, there is preliminary evidence in support of the communicative account. Parents often do not use the canonical name of an animal during a trial (e.g. "Find the red one" for lobster), suggesting that they are not (at least not always) engaging in pedagogy.

Our work contributes to the current literature on parent-child interaction, and forms the basis for further experimental work examining the influences that parent speech has on children’s language development. In line with @masur1997, our findings provide evidence that parents calibrate speech sensitively to their children's vocabulary knowledge. These results are important in light of previous work suggesting that parent responsiveness and sensitivity shapes the way young children learn language [@hoff-ginsberg1982; @tamis-lemonda2014]. Furthermore, we propose that parents are modifying their speech as a means to communicate, and that communicative intent shapes the language environments children experience. Further qualitative analysis of our dataset will shed light onto the characteristics of parent-child communication that are helpful for language acquisition.

Finally, this study highlights the importance of studying the parent-child pair as a unit, rather than viewing children as isolated learners. As argued many years ago by @hoff-ginsberg1982, both parents and children contribute to the process of language development. Focusing on the interactive and communicative nature of language captures a more realistic picture of children's language environments: the input that children receive is not random – it is sensitive to their developmental level.

# References 

```{r}
# References will be generated automatically by Pandoc and included here.
# The following code is some latex to format the bibliography. Do not remove it.
```

\setlength{\parindent}{-0.1in} 
\setlength{\leftskip}{0.125in}
\noindent
